# 一、背景知识

## 并行基本思想

- 数据并行：

  Data parallelism (e.g., SPMD)将待解决问题所需处理的数据分配给各个核，每个核在分配到的数据集上执行大致相似的操作**

  - 比如5个老师批改100份5道题的试卷，一人批改一道。

- 任务并行：

  Functional parallelism (e.g., Pipelining)将待解决问题所需要执行的各个任务分配到各个核上执行**

  - 比如5个老师批改100份5道题的试卷，将试卷分成5份，每个老师批20份试卷。

## 两种主要并行系统

### 共享内存系统(Shared Memory)

- c语言扩展POSIX threads(Pthreads)和OpenMP就是以此而设计的
- 每个核都能够读写内存的所有区域。因此可以通过检测和更新共享内存中的数据来协调各个核

### 分布式内存系统(Distributed Memory)

- C语言扩展MPI(Message-Passing Interface)就是以此而设计的
- 每个核拥有自己的私有内存，核之间的通信是显式的，必须使用类似于网络中发送消息的机制

## 并行与并发，分布式的关系

- 并行计算parallel programming:一个程序的多个任务在同一时段内可以同时执行
  - 处理多个任务但不一定同时
- 并发计算cocurrent computing:一个程序通过多个任务紧密协作来解决某个问题
  - 一定是同时处理多个任务，所以是并发的子集
- 分布式计算distributed computing:一个程序需要与其他程序协作来解决某个问题

## 进程、线程、多任务

- 操作系统operating system(os):用来管理计算机的软件和硬件资源的主要软件
  - 决定什么程序能运行以及什么时候运行
- 进程process：运行着的程序的一个实例
  - 每个进程只运行一小段时间(几毫秒)，即一个时间片。一个时间片的运行后，操作系统会切换执行其他程序。
- 线程thread：将程序划分为多个大致的独立任务，线程即某一任务的实例
  - 线程间的切换比进程间的切换更快。所以线程相对于进程是轻量级的
  - 进程可以看成主线程，一个子线程开始时从进程中派生fork出来，结束时合并join到进程中。

# 二、对冯诺依曼机构的改进

## 冯诺依曼结构

- 主存
- 中央处理单元central processing unit(cpu)
  - 寄存器register：
    - cpu中数据和程序执行时的状态信息存储在特殊的快速存储介质中，即寄存器
  - 控制单元:
    - 决定应该执行程序中的哪些指令
    - 程序计数器：控制单元的一个特殊寄存器，用来存放下一条指令的地址
  - 算术逻辑单元Arithmetic Logic Unit(ALU):
    - 执行指令
- 处理器/核
- 主存与cpu之间的互连结构（总线）
  - 指令核数据通过此来传输
  - 由于读取(数据指令从主存到CPU)和写入(数据指令从cpu到内存)的速率是不一样的。所以存在冯诺依曼瓶颈

## 结构的3种改进

- 目的：解决冯诺依曼瓶颈
- 措施：缓存caching、虚拟内存、低层次并行

### 1.缓存

- 缓存，高速缓冲存储器cache

  - 为了使内存访问能够传送更多的数据和更多的指令
  - 不再将所有的数据和指令存储再主存中，部分存储在靠近cpu寄存器的特殊存储器里，即cache

- 什么样的指令和数据可以放在Cache中？

  - 准则：程序接下来可能用到的指令和数据，与，最近访问过的指令和数据在物理上是邻近存放的

- 局部性：程序访问完一个存储区域往往会访问接下来的区域

  - 在访问完一个内存区域(指令或数据)，程序会在不久的将来(**时间局部性**)访问邻近的区域(**空间局部性**)。
  - 为了运用局部性原理，系统使用更宽的互连结构来访问指令和数据。即：一次内存访问能存取一整块代码和数据。这些块称之为**高速缓存块\高速缓存行**

- Cache有分不同层level。

  - 第一层L1最小但最快，L2、L3....越高层越大也越慢。
  - 存在L1的数据也会存在L2中，所以可以将低层Cache看作高层Cache的Cache。如果低层的某些数据没存在高层，那就会存在主存中。

- CPU访问指令、数据时，它会沿着Cache层次结构向下查询

  - Cache命中：想Cache查询信息，而Cache中有该信息时
  - Caches缺失：信息不存在时。
    - 此时，CPU会阻塞，因为它要等待速度相对更慢的主存：处理器可以停止执行当前程序的指令，直到从主存中取出所需的数据或者指令

- 当CPU向Cache中写入数据时，Cache的值和主存的值会不一致inconsistent,2种解决方法：

  - 写直达(write-through)：当cpu向cache写数据时，高速缓存行会立刻写入主存种
  - 写回(write-back)：将发生数据更新的高速缓存行标记为脏dirty。当发生高速缓存行替换时，标记为脏的高速缓存行被写入主存中。

#### Cache映射：

- 当从主存中取出一个高速缓存行时，应该把这个高速缓存行放置到cache中的什么位置。

  - 全相联fully associative:每个高速缓存行能放置在Cache中的任意位置
  - 直接映射directed mapped Cache：每个高速缓存行在Cache中有唯一的位置
  - n路组相联n-way set associated：每个高速缓存行都能放置到cache中n个不同区域位置中的一个。

- 例子：主存16行，用0-15标记。Cache4行，用0-3标记。

  - 全相联映射：主存16行可以映射到Cache中0、1、2、3任意一行。

  - 直接映射：主存行对4取余。如主存0行映射到Cache0行；1->1....15->3

  - 2路组相联映射：将cache分为2组。第0组：0、1行。第1组：2、3行。主存行对2取余，如0行可以在第0组0、1行任意一行。任意的方案是：最近最少使用least recently used.

### 2.虚拟内存

- 大型程序中，Cache中可能放不下所有的的指令和数据。使用虚拟内存，使得主存可以作为辅存的缓存。它通过在主存中存放当前执行程序所需要用到的部分，来利用时间和空间局部性。

  - 交换空间swap space中：那些暂时用不到的部分存储在辅存的块中

  - 页page：虚拟内存处理的数据块和指令块。
    - 由于比访问内存要慢几十万倍。所以页通常比较大。系统采用固定大小4-16kb

- 页表：

  - 编译程序时，给程序的页赋予虚拟页号。程序运行时，创建一张将虚拟页号映射成物理地址的表。
  - 程序运行使用到虚拟地址时，这个页表就将虚拟地址转换成物理地址。
  - 保证了程序使用的内存不会与其他程序使用的内存重叠。使得多个程序可以同时使用主存

- 转译后被缓冲区TLB，Translation-Lookaside Buffer

  - 为了解决：使用页表会增加程序总体的运行时间。

  - TLB在快速存储介质中缓存了一些页表的条目(16-512条)。利用时间和空间局部性原理，大部分存储器所访问页的物理地址已经存储在TLB中，对主存中页表的访问能够大幅度减少
  - TLB命中：查询的地址和虚拟页号在TLB中
  - TLB缺失：不在TLB中
  - 页面失效page fault:页表中该页没有合法的物理地址(不在内存中)，只存储在磁盘上。

### 3.低层次并行

- 指令级并行Instruction-Level parallelism,ILP。
  - 通过让处理器部件或者功能单元同时执行指令来提高处理器的性能。
  - 2种方法实现：
    - 流水线
      - 将功能单元分阶段安排
      - 由于延迟、各阶段运行时间不同。所以K个阶段的流水线不可能达到k倍的性能提升
    - 多发射
      - 复制功能单元，同时执行程序中的不同指令。
      - 静态多发射：功能单元是在编译时调度的
      - 动态多发射：功能单元是在运行时调度的
        - 超标量superscallar:支持动态多发射的处理器
  - 细粒度
- 线程级并行Thread-Level parallelism,TLP.
  - 通过同时执行不同线程来提供并行性。
  - 粗粒度
- 硬件多线程hardware multithreading
  - 提供一种机制：使得当前执行的任务被阻塞时，系统能够继续其他有用的工作。
  - 为保证该机制，系统必须支持线程间的快速切换。
  - 粗粒度
- 细粒度fine-grained多线程：
  - 处理器在每条指令执行完后切换线程，从而跳过被阻塞的线程。
  - 缺点：执行很长一段指令的线程时，在执行每条指令的时候都需要等待。
- 粗粒度coarse-grained多线程：
  - 只切换那些需要等待较长时间才能完成操作(如从主存种加载)而被阻塞的线程。
  - 优点：不要线程间的立即切换
- 同步多线程Simultaneous Multithreading,SMT
  - 细粒度多线程的变种没通过允许多个线程同时使用多个功能单元来利用超标量处理器的性能。

# 三、并行硬件

## 系统分类

- 单指令单数据流系统SISD(Single Instruction ,Single Data )

  - 一次执行一条指令，一次存取一个数据项。经典的冯诺依曼系统就是如此。

- 单指令多数据流系统SIMD(Single Instruction,Multiple Data)

  - 并行系统。有一个控制单元，和多个ALU。

  - 适合于对大型数组的简单循环实行并行。
  - 向量处理器，唯一广泛使用的simd系统。

- 多指令多数据流系统MIMD(Multiple Instruction, Multiple Data)

  - 有一组完全独立的处理器\核，每个核有子集的控制单元和ALU。所以MIMD系统是异步的，每个核可以按自己的节奏运行。
  - 2种类型
    - 共享内存系统
      - 一致内存访问UMA(Uniform Memory Access)系统
        - 每个核访问内存中任何一个取余的时间都相同
        - 容易编程，不用考虑不同内存区域的访问存取时间。
      - 非一致内存访问NUMA(Nonuniform Memory Access)系统
        - 每个核访问与自己相联的内存区域的速度，比访问与其他核相联的内存区域的速度快的多。
        - 能够比UMA系统使用更大容量的内存
    - 分布式内存系统
      - 集群clusters：最广泛使用的分布式内存系统
    - 混合系统
      - 一个分布式内存系统，有多个共享内存节点。

## 互联网络

- interconnection network

### 共享内存互联网络

- 最常用的2种：总线bus；交叉开关矩阵crossbar

- 总线：

  - 由一组并行通信线和控制对总线访问的硬件组成。

  - 虽然灵活且成本低。但设备一多，争夺总线的概率就增大，性能就会下降。

- 交叉开关矩阵：

  - 共享内存系统规模变大时，适合使用。
  - 交换互联网络使用交换器switch来控制相互连接设备之间的数据传递。

### 分布式内存互联网络

- 最常用2种：直接互连；间接互连。

- 直接互连：

  - 每个交换器与一个处理器-内存对直接相连，交换器之间也相互连接。
  - 等分宽度bisection width
    - 衡量同时通信的链路数目/连接性

  - 链路的带宽bandwidth
    - 链路传输数据的速度
  - 等分带宽bisection bandwidth
    - 用来衡量网络的质量
  - 全相连网络：最理想的直接互连网络

- 间接互连：

  - 通常由一些单向连接和一组处理器组成。每个处理器由一个输入链路和一个输出链路。这些链路通过一个交换网络链接。
  - 延迟latency:
    - 从发送源开始传送数据到目的地开始接收数据之间的时间
  - 带宽bandwidth
    - 目的地在开始接受数据后接收数据的速度

### MIMD系统为什么不都是共享内存

1. 共享数据结构隐式的协调多个处理器的工作，比显式的发送消息更吸引人
2. 向总线增加处理器时，访问总线发生冲突的可能性骤升。所以总线适合处理器数目小的系统
3. 大型的交叉开关矩阵很昂贵。
4. 分布式内存互联网络相对便宜。所以分布式内存系统适合那些需要大量数据和计算的问题

# 四、并行程序设计

- 并行化步骤：
  1. 划分partitioning:
     - 将要执行的指令和数据按照计算部分拆分成多个小人物。这一步的关键在于识别出可以并行执行的任务
  2. 通信communication:
     - 确定上一步锁识别出来的任务之间需要执行的那些通信
  3. 凝聚或聚合agglomeration or aggregation
     - 将第一步所确定的任务与通信结合成更大的任务
  4. 分配mapping：
     - 将上一步聚合好的任务分配到进程/线程中，这一步还要使通信量最小化，使各个进程/线程所得到的工作量大致均衡。
